{"chunks": [{"text": "Q-LEARNING CODE   import numpy as np import random  # Initialize environment parameters n_states = 5  # Example number of states n_actions = 3  # Example number of actions alpha = 0.1  # Learning rate gamma = 0.99  # Discount factor epsilon = 0.1  # Exploration rate episodes = 500  # Number of episodes  # Initialize Q-table Q = np.zeros((n_states, n_actions))  # Q-Learning algorithm for episode in range(episodes):     state = random.randint(0, n_states - 1)  # Start at a random state     done = False      while not done:         # Choose action using \u03b5-greedy         if random.uniform(0, 1) < epsilon:             action = random.randint(0, n_actions - 1)  # Explore         else:             action = np.argmax(Q[state])  # Exploit          # Simulate environment transition (Example reward and next_state)         next_state = random.randint(0, n_states - 1)         reward = random.uniform(-1, 1)  # Replace with actual reward logic          # Update Q-value using Q-Learning update rule         Q[state, action] += alpha * (reward + gamma * np.max(Q[next_state]) - Q[state, action])          # Transition to next state         state = next_state          # Example termination condition (replace with real condition)         if random.uniform(0, 1) < 0.1:             done = True  print(\"Trained Q-Table (Q-Learning):\") print(Q) .", "source": "Q-LEARNING CODE.txt"}, {"text": "Q-LEARNING CODE   import numpy as np import random  # Initialize environment parameters n_states = 5  # Example number of states n_actions = 3  # Example number of actions alpha = 0.1  # Learning rate gamma = 0.99  # Discount factor epsilon = 0.1  # Exploration rate episodes = 500  # Number of episodes  # Initialize Q-table Q = np.zeros((n_states, n_actions))  # Q-Learning algorithm for episode in range(episodes):     state = random.randint(0, n_states - 1)  # Start at a random state     done = False      while not done:         # Choose action using \u03b5-greedy         if random.uniform(0, 1) < epsilon:             action = random.randint(0, n_actions - 1)  # Explore         else:             action = np.argmax(Q[state])  # Exploit          # Simulate environment transition (Example reward and next_state)         next_state = random.randint(0, n_states - 1)         reward = random.uniform(-1, 1)  # Replace with actual reward logic          # Update Q-value using Q-Learning update rule         Q[state, action] += alpha * (reward + gamma * np.max(Q[next_state]) - Q[state, action])          # Transition to next state         state = next_state          # Example termination condition (replace with real condition)         if random.uniform(0, 1) < 0.1:             done = True  print(\"Trained Q-Table (Q-Learning):\") print(Q) .", "source": "Q-LEARNING CODE.txt"}], "document_lookup": {"0": "Q-LEARNING CODE.txt", "1": "Q-LEARNING CODE.txt"}}